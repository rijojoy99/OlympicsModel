{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf100
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fmodern\fcharset0 Courier;\f2\fnil\fcharset0 Menlo-Regular;
}
{\colortbl;\red255\green255\blue255;\red85\green142\blue40;\red102\green177\blue50;\red0\green0\blue0;
\red255\green255\blue255;\red255\green255\blue255;\red0\green116\blue0;}
{\*\expandedcolortbl;;\cssrgb\c39975\c61335\c20601;\cssrgb\c46532\c73327\c25364;\cssrgb\c0\c0\c0;
\cssrgb\c100000\c100000\c100000;\csgray\c100000;\csgenericrgb\c0\c45600\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww27860\viewh16580\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf2 ## Set Python - Spark environment.\cf0 \
import os\
import sys\
os.environ["SPARK_HOME"] = "/usr/hdp/current/spark2-client"\
os.environ["PYLIB"] = os.environ["SPARK_HOME"] + "/python/lib"\
sys.path.insert(0, os.environ["PYLIB"] + "/py4j-0.10.4-src.zip")\
sys.path.insert(0, os.environ["PYLIB"] + "/pyspark.zip")\
\
\cf2 ## Create SparkContext, SparkSession\cf0 \
from pyspark.sql import SparkSession\
from pyspark import SparkContext\
sc = SparkContext()\
spark = SparkSession(sc)\
\
\cf3 ## Verify Spark Context\cf0 \
sc
\f1\fs28 \cf4 \cb5 \expnd0\expndtw0\kerning0
\
\pard\pardeftab720\sl320\partightenfactor0
\cf4 \
from pyspark.sql.types import *\
from pyspark.sql.functions import *\
\
import numpy as np\
import StringIO\
import pandas as pd\
import warnings\
\
\cf2 # Plotting libraries\cf4 \
import matplotlib.pyplot as plt\
import seaborn as sns\
\
import plotly\
plotly.tools.set_credentials_file(username='sowjanya.pulyala18@gmail.com', api_key='Subv0KecxX4C68LwRMUp')\
\
import plotly.figure_factory as ff\
import plotly.plotly as py\
import plotly.offline as pyoff\
import plotly.graph_objs as go\
\
\cf2 # Initializing some settings\cf4 \
sns.set_style('whitegrid')\
sns.set(color_codes=True)\
warnings.filterwarnings('ignore')\
pyoff.init_notebook_mode(connected=True)\
get_ipython().magic('matplotlib inline')\
\
\
\cf3 ## Define Schema\cf4 \
finDistress_schema = StructType([\
         StructField("Target", IntegerType(), True),\
         StructField("Utilization", StringType(), True),\
         StructField("age", StringType(), True),\
         StructField("FD_ind1", StringType(), True),\
         StructField("Debt Ratio", StringType(), True),\
         StructField("Monthly Income", DoubleType(), True),\
         StructField("FD_ind2", StringType(), True),\
         StructField("FD_ind3", StringType(), True),        \
         StructField("FD_ind4", StringType(), True),\
         StructField("FD_ind5", IntegerType(), True),\
         StructField("NumberOfDependents", StringType(), True)])\
\
\
\cf2 ## Read data and create a dataframe\cf4 \
\
finDist = spark.read.format("csv")\\\
        .option("header", "false")\\\
        .option("inferSchema", "true")\\\
        .load("file:///home/1534B33/Batch33_phdData.csv", schema = finDistress_schema)\
\
\
\cf2 ## To Count the number of rows in DataFrame\cf4 \
print('Total records count is \{\}'.format(finDist.count()))\
\
\'97-Total records count is 150000\
\
\cf3 ## Columns count and column names\cf4 \
print("Total Columns count is \{\}".format(len(finDist.columns)))\
print("\\n\\nColumns are: \{\} \\n".format(finDist.columns))\
\
\'97Total Columns count is 11\
\
\cf2 # Give the percentage distribution of Target attribute and verify if it is a class imbalance problem or not.\cf4 \
\
prctDist = finDist.groupBy('Target').count() \\\
    .withColumn('total', lit(total)) \\\
    .withColumn('Percent', expr('count/total'))\
\
prctDist.show()\
\pard\tx543\pardeftab543\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \cb6 \kerning1\expnd0\expndtw0 \
\

\f2\fs22 \cf7 # Target| count| total|fraction|
\f0\fs24 \cf0 \

\f2\fs22 \cf7 # \'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97\'97
\f0\fs24 \cf0 \

\f2\fs22 \cf7 #     1| 10026|150000| 0.06684|
\f0\fs24 \cf0 \

\f2\fs22 \cf7 #     0|139974|150000| 0.93316|
\f1\fs28 \cf4 \cb5 \expnd0\expndtw0\kerning0
\
\pard\pardeftab720\sl320\partightenfactor0
\cf4 \
# Count the missing values\
\
count_of_na = finDist.na.__sizeof__()\
\
count_of_na = finDist.na.__sizeof__()\
\
\cf3 #(\'91Count of NAs =>', 32)\cf4 \
\
\
}